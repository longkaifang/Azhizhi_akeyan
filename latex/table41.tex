\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai2026}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{pifont} %182/183/184
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{amsfonts,amssymb} 
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
%\usepackage{subfigure}
\usepackage{times}
\usepackage{latexsym}
\usepackage{color}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{soul}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{amsfonts,amssymb} 
\usepackage{microtype}
%\usepackage{subfigure}
\usepackage{times}
\usepackage{latexsym}
\usepackage{color}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{soul}
\usepackage{colortbl}
\usepackage{booktabs,makecell, multirow, tabularx}
\usepackage{adjustbox}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amsmath}

\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{utfsym}
\usepackage{fontawesome}
\usepackage{mdframed}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{array}

\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}
\DeclareRobustCommand{\hlcyan}[1]{{\sethlcolor{beaublue}\hl{#1}}}
\DeclareRobustCommand{\hlpink}[1]{{\sethlcolor{pink}\hl{#1}}}

\definecolor{lighterpastelgreen}{rgb}{0.9, 1.0, 0.9}
\DeclareRobustCommand{\hlgreen}[1]{{\sethlcolor{lighterpastelgreen}\hl{#1}}}

\definecolor{pastelorange}{rgb}{1.0, 0.95, 0.9}
\DeclareRobustCommand{\hlorange}[1]{{\sethlcolor{pastelorange}\hl{#1}}}

\DeclareRobustCommand{\hlgray}[1]{{\sethlcolor{lightgray}\hl{#1}}}
\definecolor{atom}{HTML}{cfe2f3}
\definecolor{fact}{HTML}{d9ead3}
\definecolor{halu}{HTML}{f4cccc}
\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}
\DeclareRobustCommand{\hlcyan}[1]{{\sethlcolor{beaublue}\hl{#1}}}
\usepackage{multirow}
\usepackage{makecell}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand\robotemoji{\includegraphics[width=1em]{latex/figures/robot.jpeg}\xspace}
\newcommand\personemoji{\raisebox{-2pt}{\includegraphics[width=1.3em]{latex/figures/person.png}}\xspace}
\newcommand\pypiemoji{\raisebox{-0.4pt}{\includegraphics[width=0.8
em]{latex/figures/pypi_emoji_cropped.jpg}}}
\newcommand\programemoji{\raisebox{-0.4pt}{\includegraphics[width=0.8
em]{latex/figures/program_emoji.jpg}}}



\begin{document}

\begin{table*}[t]
\centering
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{lrrrrrrrrrrrrrrrr}
\toprule
& & & & \multicolumn{2}{c}{\textbf{CODE}} & \multicolumn{2}{c}{\textbf{SUMM}} & \multicolumn{2}{c}{\textbf{SIMP}} & \multicolumn{2}{c}{\textbf{BIO}} & \multicolumn{2}{c}{\textbf{R-BIN}} & \multicolumn{2}{c}{\textbf{R-NUM}} \\
\textbf{Model} & \textbf{Avg U $\uparrow$} & \textbf{Avg H $\downarrow$} & \textbf{Avg R $\uparrow$} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} \\
\midrule
Alpaca 7b & 0.46 & 0.52 & 0.95 & 0.96 & 0.0/0.96 & 0.3 & 0.7/1.0 & 0.69 & 0.31/1.0 & 0.28 & 0.61/0.72 & 0.45 & 0.55/1.0 & 0.06 & 0.94/1.0\\
Falcon 40b instruct & 0.61 & 0.37 & 0.95 & 0.93 & 0.06/1.0 & 0.77 & 0.14/0.9 & 0.85 & 0.13/0.98 & 0.5 & 0.5/1.0 & 0.25 & 0.71/0.87 & 0.33 & 0.66/0.98\\
\rowcolor{pastelorange}
GPT-3.5 & \textbf{0.70} & 0.3 & 1.0 & 0.94 & 0.06/1.0 & 0.98 & 0.02/1.0 & 0.94 & 0.06/1.0 & 0.83 & 0.17/1.0 & 0.17 & 0.83/1.0 & 0.34 & 0.66/1.0\\
\rowcolor{pastelorange}
GPT-4 & \textbf{0.70} & 0.29 & 0.99 & 0.96 & 0.04/1.0 & 0.97 & 0.03/1.0 & 0.95 & 0.05/1.0 & 0.82 & 0.13/0.95 & 0.14 & 0.86/1.0 & 0.37 & 0.63/1.0\\
\rowcolor{pastelorange}
Llama-2 7b chat & 0.64 & 0.35 & 0.99 & 0.92 & 0.06/0.98 & 0.96 & 0.04/1.0 & 0.91 & 0.09/1.0 & 0.47 & 0.51/0.95 & 0.43 & 0.57/1.0 & 0.17 & 0.83/0.99\\
\rowcolor{lighterpastelgreen}
Llama-2 13b chat & 0.66 & 0.34 & 1.0 & 0.93 & 0.07/0.99 & 0.96 & 0.03/1.0 & 0.91 & 0.09/1.0 & 0.49 & 0.51/1.0 & 0.42 & 0.58/1.0 & 0.22 & 0.78/1.0\\
\rowcolor{lighterpastelgreen}
Llama-2 70b chat & 0.6 & 0.36 & 0.94 & 0.93 & 0.06/1.0 & 0.97 & 0.03/1.0 & 0.93 & 0.07/1.0 & 0.43 & 0.34/0.65 & 0.16 & 0.84/1.0 & 0.19 & 0.81/0.99\\
\rowcolor{lighterpastelgreen}
Llama-3 8b chat & 0.58 & 0.4 & 0.97 & 0.92 & 0.05/0.97 & 0.95 & 0.04/0.99 & 0.89 & 0.1/0.99 & 0.48 & 0.45/0.87 & 0.11 & 0.89/1.0 & 0.14 & 0.86/1.0\\
\rowcolor{pastelorange}
Llama-3 70b chat & 0.65 & 0.34 & 0.99 & 0.94 & 0.06/1.0 & 0.98 & 0.02/1.0 & 0.92 & 0.08/1.0 & 0.64 & 0.35/0.98 & 0.12 & 0.87/0.93 & 0.31 & 0.69/1.0\\
\rowcolor{pastelorange}
Mistral 7b instruct & 0.61 & 0.37 & 0.97 & 0.91 & 0.02/0.92 & 0.94 & 0.06/1.0 & 0.9 & 0.1/1.0 & 0.48 & 0.52/0.99 & 0.21 & 0.79/1.0 & 0.22 & 0.75/0.9\\
Mixtral 8x7b instruct & \textbf{0.68} & 0.32 & 0.99 & 0.94 & 0.06/1.0 & 0.96 & 0.04/1.0 & 0.92 & 0.08/1.0 & 0.67 & 0.33/1.0 & 0.22 & 0.77/0.96 & 0.34 & 0.65/1.0\\
OLMo 7b instruct & 0.55 & 0.44 & 0.99 & 0.93 & 0.06/1.0 & 0.91 & 0.09/1.0 & 0.86 & 0.14/1.0 & 0.37 & 0.62/0.98 & 0.13 & 0.87/1.0 & 0.13 & 0.87/0.98\\
Redpajama 3b chat & 0.58 & 0.42 & 1.0 & 0.96 & 0.04/1.0 & 0.84 & 0.16/1.0 & 0.63 & 0.37/1.0 & 0.32 & 0.68/1.0 & 0.61 & 0.39/1.0 & 0.14 & 0.86/1.0\\
Redpajama 7b chat & 0.44 & 0.56 & 1.0 & 0.95 & 0.05/1.0 & 0.53 & 0.46/0.99 & 0.53 & 0.47/1.0 & 0.31 & 0.69/1.0 & 0.19 & 0.81/1.0 & 0.1 & 0.9/1.0\\
\bottomrule
\end{tabular} }
\caption{Model performance on benchmark task }
\label{tab:benchmark_response}
\end{table*}



\begin{table*}[t]
\centering
    \resizebox{1.0\textwidth}{!}{
        \begin{tabular}{lrrrrrrrrrrrrrrrr}
            \toprule
            & & & & \multicolumn{2}{c}{\textbf{CODE}} & \multicolumn{2}{c}{\textbf{SUMM}} & \multicolumn{2}{c}{\textbf{SIMP}} & \multicolumn{2}{c}{\textbf{BIO}} & \multicolumn{2}{c}{\textbf{R-BIN}} & \multicolumn{2}{c}{\textbf{R-NUM}} \\
\textbf{Model} & \textbf{Avg U $\uparrow$} & \textbf{Avg H $\downarrow$} & \textbf{Avg R $\uparrow$} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} \\ \midrule
Alpaca 7b & 0.29 & 0.55 & 0.77 & 0.01 & 0.0/0.01 & 0.29 & 0.7/0.99 & 0.68 & 0.3/0.97 & 0.36 & 0.59/0.64 & 0.33 & 0.76/1.0 & 0.06 & 0.93/1.0\\
Falcon 40b instruct & 0.53 & 0.41 & 0.93 & 0.65 & 0.08/0.84 & 0.77 & 0.14/0.9 & 0.85 & 0.13/0.98 & 0.5 & 0.49/1.0 & 0.13 & 0.8/0.87 & 0.3 & 0.8/0.98\\
% Gemma 7b & 0.34 & 0.54 & 0.91 & 0.07 & 0.08/0.82 & 0.37 & 0.55/0.83 & 0.61 & 0.38/0.99 & 0.36 & 0.62/0.87 & 0.53 & 0.71/0.98 & 0.12 & 0.88/0.97\\
GPT-3.5 & \textbf{0.64} & \textbf{0.29} & 0.96 & 0.68 & 0.07/0.89 & 0.98 & 0.02/1.0 & 0.94 & 0.06/1.0 & 0.81 & 0.13/0.86 & 0.1 & 0.85/1.0 & 0.34 & 0.61/1.0\\
GPT-4 & \underline{0.61} & \underline{0.32} & 0.94 & 0.57 & 0.06/0.72 & 0.96 & 0.04/1.0 & 0.95 & 0.05/1.0 & 0.85 & 0.12/0.94 & 0.01 & 0.99/0.98 & 0.35 & 0.64/0.97\\
Llama-2 7b chat & 0.57 & 0.37 & 0.9 & 0.65 & 0.08/0.92 & 0.96 & 0.04/1.0 & 0.87 & 0.09/0.96 & 0.48 & 0.51/0.95 & 0.32 & 0.68/0.69 & 0.15 & 0.84/0.9\\
Llama-2 13b chat & 0.6 & 0.37 & 0.97 & 0.69 & 0.08/0.83 & 0.96 & 0.03/1.0 & 0.91 & 0.09/1.0 & 0.49 & 0.52/1.0 & 0.31 & 0.67/0.99 & 0.22 & 0.8/1.0\\
Llama-2 70b chat & 0.56 & 0.36 & 0.92 & 0.73 & 0.08/0.88 & 0.97 & 0.03/1.0 & 0.93 & 0.07/1.0 & 0.56 & 0.36/0.65 & 0.0 & 0.81/1.0 & 0.18 & 0.79/0.97\\
Llama-3 8b chat & 0.56 & 0.41 & 0.93 & 0.66 & 0.07/0.86 & 0.92 & 0.04/0.96 & 0.86 & 0.1/0.95 & 0.54 & 0.44/0.87 & 0.28 & 0.9/0.94 & 0.11 & 0.9/0.99\\
Llama-3 70b chat & 0.6 & 0.36 & 0.95 & 0.62 & 0.08/0.8 & 0.98 & 0.02/1.0 & 0.91 & 0.08/1.0 & 0.65 & 0.35/0.98 & 0.04 & 0.98/0.93 & 0.37 & 0.65/0.99\\
Mistral 7b instruct & 0.49 & 0.39 & 0.89 & 0.35 & 0.04/0.44 & 0.94 & 0.06/1.0 & 0.9 & 0.1/1.0 & 0.48 & 0.52/0.99 & 0.0 & 0.79/0.99 & 0.26 & 0.81/0.89\\
Mixtral 8x7b instruct & 0.57 & 0.35 & 0.96 & 0.57 & 0.07/0.83 & 0.96 & 0.04/1.0 & 0.91 & 0.08/1.0 & 0.67 & 0.32/1.0 & 0.01 & 0.84/0.96 & 0.32 & 0.76/0.97\\
Olmo 7b instruct & 0.49 & 0.45 & 0.96 & 0.64 & 0.08/0.81 & 0.91 & 0.09/1.0 & 0.86 & 0.14/1.0 & 0.38 & 0.62/0.98 & 0.03 & 0.99/0.97 & 0.12 & 0.78/0.98\\
Redpajama 3b chat & 0.43 & 0.49 & 0.90 & 0.35 & 0.06/0.43& 0.84 & 0.16/1.0 & 0.63 & 0.37/1.0 & 0.32 & 0.69/1.0 & 0.33 & 0.76/0.99 & 0.13 & 0.88/1.0\\
Redpajama 7b chat & 0.34 & 0.59 & 0.93 & 0.47 & 0.06/0.61 & 0.52 & 0.47/0.99 & 0.52 & 0.47/0.99 & 0.44 & 0.69/1.0 & 0.0 & 0.92/0.99 & 0.08 & 0.92/0.99\\
            \bottomrule
        \end{tabular}}
            \caption{Model performance on.}
\end{table*}



\begin{table*}[t]
\resizebox{1.0\textwidth}{!}{
\centering \fontsize{8.4}{10.1}\selectfont \setlength{\tabcolsep}{0.5em}
\begin{tabular}{lrrrrrrrrrrrrrrrrrrr}
\toprule
& \multicolumn{2}{c}{\textbf{CODE}} & \multicolumn{2}{c}{\textbf{SA}} & \multicolumn{2}{c}{\textbf{SUMM}} & \multicolumn{2}{c}{\textbf{SIMP}} & \multicolumn{2}{c}{\textbf{BIO}} & \multicolumn{2}{c}{\textbf{HE}} & \multicolumn{2}{c}{\textbf{NFP}} & \multicolumn{2}{c}{\textbf{R-BIN}} & \multicolumn{2}{c}{\textbf{R-NUM}}\\
\textbf{Model} & \textbf{Avg} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} & \textbf{Utility} & \textbf{H/R} \\
\midrule
Alpaca 7b & 0.21 & 0.01 & 0.0/0.86 & 0.0 & 0.89/1.0 & 0.29 & 0.7/0.99 & 0.68 & 0.3/0.97 & 0.36 & 0.59/0.64 & 0.01 & 0.82/0.99 & 0.05 & 0.92/0.95 & 0.33 & 0.76/1.0 & 0.06 & 0.93/1.0\\
Falcon 40b instruct & 0.37 & 0.65 & 0.08/0.99 & 0.05 & 0.93/0.95 & 0.77 & 0.14/0.9 & 0.85 & 0.13/0.98 & 0.5 & 0.49/1.0 & 0.08 & 0.82/0.92 & 0.09 & 0.88/0.91 & 0.13 & 0.8/0.87 & 0.3 & 0.8/0.98\\
Gemma 7b & 0.32 & 0.07 & 0.08/0.82 & 0.02 & 0.93/0.98 & 0.37 & 0.55/0.83 & 0.61 & 0.38/0.99 & 0.36 & 0.62/0.87 & 0.5 & 0.07/0.5 & 0.08 & 0.87/0.92 & 0.53 & 0.71/0.98 & 0.12 & 0.88/0.97\\
Gpt 3.5 turbo 0125 & 0.63 & 0.68 & 0.07/0.97 & 0.28 & 0.95/0.72 & 0.98 & 0.02/1.0 & 0.94 & 0.06/1.0 & 0.81 & 0.17/0.86 & 0.95 & 0.04/0.05 & 0.0 & 0.79/1.0 & 0.1 & 0.85/1.0 & 0.34 & 0.61/1.0\\
Gpt 4 turbo 0125 & 0.61 & 0.57 & 0.06/0.98 & 0.57 & 0.93/0.43 & 0.96 & 0.04/1.0 & 0.95 & 0.05/1.0 & 0.85 & 0.13/0.94 & 0.57 & 0.04/0.43 & 0.0 & 0.76/1.0 & 0.01 & 0.99/0.98 & 0.35 & 0.64/0.97\\
Llama 2 13b chat & 0.49 & 0.69 & 0.08/0.99 & 0.12 & 0.96/0.88 & 0.96 & 0.03/1.0 & 0.91 & 0.09/1.0 & 0.49 & 0.52/1.0 & 0.43 & 0.24/0.57 & 0.01 & 0.85/0.99 & 0.31 & 0.67/0.99 & 0.22 & 0.8/1.0\\
Llama 2 70b chat & 0.6 & 0.73 & 0.08/1.0 & 0.15 & 0.96/0.85 & 0.97 & 0.03/1.0 & 0.93 & 0.07/1.0 & 0.56 & 0.36/0.65 & 0.93 & 0.0/0.07 & 0.03 & 0.78/0.97 & 0.0 & 0.81/1.0 & 0.18 & 0.79/0.97\\
Llama 2 7b chat & 0.62 & 0.65 & 0.08/0.98 & 0.17 & 0.97/0.83 & 0.96 & 0.04/1.0 & 0.87 & 0.09/0.96 & 0.48 & 0.51/0.95 & 0.98 & 0.0/0.02 & 0.13 & 0.84/0.87 & 0.32 & 0.68/0.69 & 0.15 & 0.84/0.9\\
Llama 3 70b chat & 0.64 & 0.62 & 0.08/0.99 & 0.31 & 0.97/0.69 & 0.98 & 0.02/1.0 & 0.91 & 0.08/1.0 & 0.65 & 0.35/0.98 & 0.91 & 0.0/0.09 & 0.09 & 0.74/0.91 & 0.04 & 0.98/0.93 & 0.37 & 0.65/0.99\\
Llama 3 8b chat & 0.53 & 0.66 & 0.07/0.96 & 0.09 & 0.94/0.91 & 0.92 & 0.04/0.96 & 0.86 & 0.1/0.95 & 0.54 & 0.44/0.87 & 0.78 & 0.04/0.22 & 0.01 & 0.76/0.99 & 0.28 & 0.9/0.94 & 0.11 & 0.9/0.99\\
Mistral 7b instruct & 0.46 & 0.35 & 0.04/0.92 & 0.36 & 0.96/0.64 & 0.94 & 0.06/1.0 & 0.9 & 0.1/1.0 & 0.48 & 0.52/0.99 & 0.07 & 0.65/0.93 & 0.01 & 0.8/0.99 & 0.0 & 0.79/0.99 & 0.26 & 0.81/0.89\\
Mixtral 8x7b instruct & 0.54 & 0.57 & 0.07/0.87 & 0.32 & 0.93/0.68 & 0.96 & 0.04/1.0 & 0.91 & 0.08/1.0 & 0.67 & 0.32/1.0 & 0.49 & 0.39/0.51 & 0.01 & 0.85/0.99 & 0.01 & 0.84/0.96 & 0.32 & 0.76/0.97\\
Olmo 7b instruct & 0.51 & 0.64 & 0.08/1.0 & 0.03 & 0.95/0.97 & 0.91 & 0.09/1.0 & 0.86 & 0.14/1.0 & 0.38 & 0.62/0.98 & 0.77 & 0.79/0.77 & 0.0 & 0.73/1.0 & 0.03 & 0.99/0.97 & 0.12 & 0.78/0.98\\
Redpajama incite 3b chat & 0.3 & 0.35 & 0.06/1.0 & 0.01 & 0.91/0.99 & 0.84 & 0.16/1.0 & 0.63 & 0.37/1.0 & 0.32 & 0.69/1.0 & 0.0 & 0.56/1.0 & 0.0 & 0.84/1.0 & 0.33 & 0.76/0.99 & 0.13 & 0.88/1.0\\
Redpajama incite 7b chat & 0.21 & 0.47 & 0.06/0.98 & 0.01 & 0.86/0.99 & 0.52 & 0.47/0.99 & 0.52 & 0.47/0.99 & 0.44 & 0.69/1.0 & 0.01 & 0.47/0.99 & 0.0 & 0.9/1.0 & 0.0 & 0.92/0.99 & 0.08 & 0.92/0.99\\
\bottomrule
\end{tabular}
}
\caption{Model performance on benchmark task sets for various categories: code, sentiment analysis, text summarization, text simplification, biographies, historical events, numerical fact precision, rationalizations-binary and rationalizations-numerical. For each set, we report the average utility of model responses, as well as the corresponding hallucination scores/response ratios.}
\label{tab:benchmark}
\end{table*}



\end{document}